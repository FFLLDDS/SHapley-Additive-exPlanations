{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP to explain MNIST classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data'\n",
    "BATCHSIZE = 64\n",
    "LR = 1e-3\n",
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(root=PATH, train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.MNIST(root=PATH, train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCHSIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCHSIZE ,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "                                            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3), \n",
    "                                            nn.BatchNorm2d(4), \n",
    "                                            nn.ReLU(), \n",
    "                                            # input_size: (BATCHSIZE, 4, 26, 26)\n",
    "                                            nn.Conv2d(in_channels=4, out_channels=16, kernel_size=4, stride=2), \n",
    "                                            nn.BatchNorm2d(16), \n",
    "                                            nn.ReLU(), \n",
    "                                            # input_size: (BATCHSIZE, 16, 12, 12)\n",
    "                                            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3), \n",
    "                                            nn.ReLU(), \n",
    "                                            # output_size: (BATCHSIZE, 8, 10, 10)\n",
    "            )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "                                            nn.Linear(8*10*10, 100), \n",
    "                                            nn.ReLU(), \n",
    "                                            nn.Linear(100, 10)#, \n",
    "                                            # nn.Softmax(dim=1) (*)\n",
    "        )\n",
    "            \n",
    "    def forward(self, x): \n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 8*10*10)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train()\n",
    "\n",
    "losses = []\n",
    "\n",
    "print('Start training classifier...')\n",
    "for epoch in range(NUM_EPOCHS): \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader): \n",
    "        imgs, labels = batch\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        preds = classifier(imgs)\n",
    "        loss = criterion(preds, labels) # preds.log() (*)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # collect stats\n",
    "        losses.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # print stats\n",
    "        if i % 200 == 199:\n",
    "            print(f'[{epoch+1}/{NUM_EPOCHS}] [{i+1}/{len(train_loader)}] Loss classifier: {running_loss / 200}')\n",
    "            running_loss = 0.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title('training loss')\n",
    "plt.xlabel('batches')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.eval()\n",
    "\n",
    "with torch.no_grad():    \n",
    "    correct = 0.0\n",
    "    num_test_imgs = 0\n",
    "\n",
    "    for batch in test_loader: \n",
    "        imgs, labels = batch\n",
    "        \n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        preds_raw = classifier(imgs)\n",
    "        preds = torch.argmax(preds_raw, dim=1)\n",
    "        \n",
    "        correct += (preds == labels).sum().item() \n",
    "        num_test_imgs += len(labels)\n",
    "        \n",
    "    print(f'The accuracy of the classifier is: {correct / num_test_imgs:.3f}')\n",
    "\n",
    "\n",
    "    imgs, labels = next(iter(train_loader))\n",
    "    imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "    out_raw = classifier(imgs)\n",
    "    out = torch.argmax(out_raw, dim=1)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    fig.suptitle('(label, prediction)')\n",
    "\n",
    "    for i in range(len(imgs)): \n",
    "        plt.subplot(8, 8, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(imgs[i].squeeze().detach().cpu().numpy())\n",
    "        plt.title(f'{labels[i].item(), out[i].item()}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP $ \\text{\\scriptsize (see example in SHAP documentation)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since shuffle=True, this is a random sample of test data\n",
    "batch = next(iter(test_loader))\n",
    "images, _ = batch\n",
    "\n",
    "images = images.to(device)\n",
    "\n",
    "background = images[:50]\n",
    "test_images = images[50:53]\n",
    "\n",
    "e = shap.DeepExplainer(classifier, background)\n",
    "shap_values = e.shap_values(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
    "test_numpy = np.swapaxes(np.swapaxes(test_images.cpu().numpy(), 1, -1), 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the feature attributions\n",
    "shap.image_plot(shap_numpy, -test_numpy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e38f0c188ce6a35b54fcffb420782e7c865c9fec8ce80c6a870b6cb8f84f9de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('island': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
